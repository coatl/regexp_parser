= Regexp::Parser

  Note "This project is in its early stages of development."
  Warn "Names and structures are still moving and changing."


== What?
A ruby library to help with lexing, parsing, and transforming regular expressions.

* Multilayered

  * A scanner based on ragel[http://www.complang.org/ragel/]
  * A lexer that produces a "stream" of tokens
  * A parser that produces a "tree" of Regexp::Expression objects (OO API)

* Lexes and parses several regular expression flavors

    # Initial focus
      # Ruby 1.8/1.9    ** In progress
      # POSIX BRE/ERE   ** In progress

    # Being considered for inclusion
      # ARE (Tcl)
      # GNU (BRE/ERE with some extensions)
      # Java
      # JavaScript
      # PCRE
      # PERL
      # PHP (ERE for ereg, PCRE for preg)
      # Python
      # XML
      # XPath
      # .NET

* Supports ruby 1.8 and 1.9 runtime


== Components
=== Scanner
A ragel generated scanner that recognizes the cumulative syntax of all
supported flavors (this might change soon). Breaks the expression's text
into tokens, including their type, token (id), text, and start/end offsets
within the original pattern.

==== Example
The following scans the given pattern and prints out the type, token, text and
start/end offsets for each token found.

  require 'regexp_parser'

  Regexp::Scanner.scan /(ab?(cd)*[e-h]+)/  do |type, token, text, ts, te|
    puts "type: #{type}, token: #{token}, text: '#{text}' [#{ts}..#{te}]"
  end

A one-liner that returns an array of the textual parts of the given pattern:

  Regexp::Scanner.scan( /(cat?([b]at)){3,5}/ ).map {|token| token[2]}
  #=> ["(", "cat", "?", "(", "[", "b", "]", "at", ")", ")", "{3,5}"]


==== Notes
  * Does basic syntax error checking, like detecting missing balancing
    punctuation and premature end of pattern. Flavor validity checks are
    performed in the lexer.

  * To keep the scanner simple(r) and fairly reusable for other uses, it
    does not perform lexical analysis on the tokens, sticking to the task
    of tokenizing and leaving lexical analysis upto to the lexer as well.

  * If the input is a ruby Regexp object, the scanner calls #source on it to
    get its string representation. #source does not include the options of
    expression (m, i, etc.) To include the options the process, #to_s should
    be called on the Regexp before passing it to the scanner, or any of the
    higher layers. Obviously this only works for ruby regular expressions.

==== TODO
  * Consider extracting a "baseline" scanner common to all flavors, and layer
    subsets of syntax into individual ragel machines, like assertions, posix
    classes and unicode properties.

  * Add a machine for escaped strings, usable from other machines.


---
=== Syntax
Defines the supported lexem types and tokens for specific engine implementation
(aka a flavor). Syntax classes act as lookup tables, and can be layered to
create flavor variations.

==== Example
The following instantiates the syntax for Ruby 1.9 and checks a couple of its
implementations features, and then does the same for Ruby 1.8:

  require 'regexp_parser'

  ruby_19 = Regexp::Syntax.new 'ruby/1.9'
  ruby_19.implements? :quantifier, :zero_or_one             # => true
  ruby_19.implements? :quantifier, :zero_or_one_reluctant   # => true
  ruby_19.implements? :quantifier, :zero_or_one_possessive  # => true

  ruby_18 = Regexp::Syntax.new 'ruby/1.8'
  ruby_18.implements? :quantifier, :zero_or_one             # => true
  ruby_18.implements? :quantifier, :zero_or_one_reluctant   # => false
  ruby_18.implements? :quantifier, :zero_or_one_possessive  # => false


==== Notes
  * Variatiions on a token, for example a named group with < and > vs one with a
    pair of single quotes, *will be* specified as an underscore followed by two
    characters appended to the base token. In the previous named group example,
    the tokens would be :named_ab (angle brackets) and :named_sq (single quotes).
    This should simplify specifying syntax that includes multiple variations by
    testing/removing the last 3 characters. 

==== TODO
  * A lot. Complete Ruby and POSIX flavors first.

  * Add flavor limits: like Ruby 1.8's maximum allowed number of grouped 
    expressions (253).


---
=== Lexer
Sits on top of the scanner, and performs lexical analysis on the tokens that
it emits. Among its tasks are breaking quantified literal runs, collecting the
emitted token structures into an array of Token objects, calculating their
nesting depth, normalizing tokens for the parser, and checkng if the tokens
are implemented by a given syntax flavor.

Tokens objects are Structs, basically data objects, with a few helper methods,
like #next, #previous, #offsets and #length.

==== Example
The following example scans the given pattern, checks it against the ruby 1.8
syntax, and prints the token objects' text.

  require 'regexp_parser'

  Regexp::Lexer.scan /a?(b)*[c]+/, 'ruby/1.8'  do |token|
    puts "#{'  ' * token.depth}#{token.text}"
  end

A one-liner that returns an array of the textual parts of the given pattern. Compare the output with that of the one-liner example of the Scanner.

  Regexp::Lexer.scan( /(cat?([b]at)){3,5}/ ).map {|token| token.text}
  #=> ["(", "ca", "t", "?", "(", "[", "b", "]", "at", ")", ")", "{3,5}"]

==== Notes
  * The lexer performs some basic parsing to determine the depth of a the
    emitted tokens. This responsibility might be relegated to the scanner.

==== TODO
  * Consider normalizing token variations in the lexer to simplify parser
    layer's code, for example BRE's escaped groupings to abstract grouping
    tokens.

  * Consider breaking the interval quantifier into individual tokens as:
    :open, :min, :min_default, :comma, :max, :max_default, :exact, :close. 
    Adding :exact will require lookahead or a separate state in the scanner.

  * If tokens are broken further, like interval, consider adding a "combine"
    option in the lexer that can merge them into single strings.


---
=== Parser
Sits on top of the lexer and transforms the "stream" of Token objects emitted
by it into a tree of Expression objects represented by an instance of the
Expression::Root class. See Expression below for more information.

==== Example

  require 'regexp_parser'

  root = Regexp::Parser.parse /a?(b)*[c]+)/m, 'posix/ere'

  root.multiline?   # => true (aliased as m?)
  root.insensitive? # => false (aliased as i?)

  root.expressions.each do |exp|
    if exp.quantified?
      puts "#{exp.clas.name}: is quantified, min: #{exp.min}, #{exp.max}"
    end
  end


---
=== Expression
The base class of all objects returned by the parser, implements most of the
functions of all expression classes.

==== TODO
  * Implementing to_s and to_re requires saving open/close token text, including
    quantifiers since the parser coalesces the two into a single object.



== Scanner Syntax
The following is targeted for support by the scanner. This should be a table,
but RDoc doesn't support such things. Will revisit properly in a wiki... soon.

  - Alternation: a|b|c                          ** PARSER
  - Anchors: ^, $, \b, etc.                     ** PARSER
  - Character Classes (aka Sets): [abc], [^\]]  ** SCANNER (missing nested sets)
  - Character Types: \d, \H, \s, etc.           ** PARSER
  - Escape Sequences
    - Backreference: \1 thru \9                 ** SCANNER
    - Metacharacters: \\, \+, \?, etc.          ** SCANNER

  - Grouped Expressions
    - Atomic: (?>abc)                           ** SCANNER
    - Back-references: \k<name>, \k<1>, \k<-2>  ** SCANNER (missing nested e.g. \k<name-1> and \k<num-1>)
    - Capturing: (abc)                          ** SCANNER
    - Comment: (?# comment)                     ** SCANNER
    - Named: (?<name>abc)                       ** SCANNER
    - Options: (?mi-x:abc)                      ** SCANNER (missing u, e, etc)
    - Passive: (?:abc)                          ** SCANNER
    - Assertions
      - Lookahead: (?=abc)                      ** SCANNER
      - Negative Lookahead: (?!abc)             ** SCANNER
      - Lookabehind: (?<=abc)                   ** SCANNER
      - Negative Lookbehind: (?<\!abc)          ** SCANNER
    - Sub-expression Calls: \g<name>, \g<1>     ** SCANNER

  - Literals: abc, def?                         ** LEXER - REVIEW/TEST
  - POSIX classes: [:alpha:], [:print:], etc.   ** SCANNER
  - Quantifiers
    - Greedy: ?, *, +, {m,M}                    ** PARSER
    - Reluctant: ??, *?, +?, {m,M}?             ** PARSER
    - Possessive: ?+, *+, ++, {m,M}+            ** PARSER

  - String Escapes
    - Control: \C-C, \cD                        ** SCANNER
    - Hex: \x20, \x{701230}                     ** SCANNER
    - Meta: \M-c, \M-\C-C etc..                 ** REVIEW/TEST
    - Octal: \0, \01, \012                      ** SCANNER
    - Unicode: \uHHHH, \u{H+ H+}                ** SCANNER

  - Unicode Properties: 
    - Age: \p{2.1}, \P{5.2}, etc.               ** SCANNER
    - Classes: \p{Alpha}, \P{Space}, etc.       ** SCANNER
    - Derived Properties: \p{Math} etc.         ** SCANNER
    - General Categories: \p{Lu}, \P{Cs}, etc.  ** SCANNER
    - Scripts: \p{Arabic}, \P{Hiragana}         ** SCANNER
    - Simple Properties (aka Aliases):          ** MISSING


  Notes with ** mean:
    MISSING:      nothing in place, or barely there
    REVIEW/TEST:  mostly there (scanner and/or lexer), but has no tests, or has problems
    SCANNER:      implemented in scanner, works, has basic tests
    LEXER:        implemented in lexer, works, has basic tests
    PARSER:       implemented parser, works, has basic tests
    COMPLETE:     Fully implemented in the scanner, lexer, and parser


== References
Documentation and information being read while working on this project.

==== Ruby Flavor
* Oniguruma Regular Expressions link[http://www.geocities.jp/kosako3/oniguruma/doc/RE.txt]
* Read Ruby > Regexps link[http://ruby.runpaint.org/regexps]
* TextMate (uses Oniguruma) Manual: Regular Expressions link[http://manual.macromates.com/en/regular_expressions]

==== POSIX Flavors
* BRE/ERE link[http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html#tag_09_05_01]

==== Other Flavors
* GNU: link[http://www.delorie.com/gnu/docs/regex/regex_toc.html]
* PCRE link[http://www.pcre.org/pcre.txt]
* PERL link[http://perldoc.perl.org/perlreref.html]
* POSIX link[http://www.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html]
* TRE link[http://laurikari.net/tre/documentation/regex-syntax/]

==== General
* GNU Comparisons link[http://www.greenend.org.uk/rjk/2002/06/regexp.html]
* Enumerating the strings of regular languages link[http://www.cs.dartmouth.edu/~doug/nfa.ps.gz]
* Mastering Regular Expressions, By Jeffrey E.F. Friedl (1st Edition) book[http://oreilly.com/catalog/9781565922570/]
* Regular Expression Flavor Comparison link[http://www.regular-expressions.info/refflavors.html]
* Regular Expression Matching: the Virtual Machine Approach link[http://swtch.com/~rsc/regexp/regexp2.html]

==== Unicode
* Unicode Derived Properties link[http://www.unicode.org/Public/UNIDATA/DerivedCoreProperties.txt]
* Unicode Explained, By Jukka K. Korpela. book[http://oreilly.com/catalog/9780596101213]
* Unicode Property Aliases link[http://www.unicode.org/Public/UNIDATA/PropertyAliases.txt]
* Unicode Regular Expressions link[http://www.unicode.org/reports/tr18/]
* Unicode Standard Annex #44 link[http://www.unicode.org/reports/tr44/]

== Thanks
This work is based on and inspired by the hard work and ideas of many people,
directly or indirectly. The following are only a few of those that should be 
thanked.

* Adrian Thurston, for developing ragel[http://www.complang.org/ragel/].
* Caleb Clausen, for feedback, which inspired this,  valuable insights on structuring the parser,
  and lots of cool code[http://github.com/coatl].
* Jan Goyvaerts, for his excellent resource[http://www.regular-expressions.info] on regular expressions. I owe him a "steak dinner", at least.
* Run Paint Run Run, for his work on Read[http://ruby.runpaint.org/] Ruby
* Yukihiro Matsumoto, of course! For "The Ruby", of course!

== Copyright
Copyright (c) 2010 Ammar Ali. See LICENSE file for details.
